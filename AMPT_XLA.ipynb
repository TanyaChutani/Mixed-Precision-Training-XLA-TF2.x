{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMPT-XLA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twiWiPE-2rbT",
        "outputId": "ab215214-d0ec-4437-e52e-1506c6fe4180"
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "\n",
        "def data_generator(features,labels,batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((tf.cast((features/255),tf.float32),labels))\n",
        "  dataset = dataset.shuffle(buffer_size=len(labels)+1)\n",
        "  dataset = dataset.batch(batch_size=batch_size,\n",
        "                          drop_remainder=True)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return dataset\n",
        "\n",
        "def model(num_classes):  \n",
        "  model_input = tf.keras.layers.Input(shape=(32,32,3),dtype=tf.float32)\n",
        "  model = tf.keras.applications.ResNet50(include_top=False,\n",
        "                                            pooling='avg',\n",
        "                                         input_tensor=model_input)\n",
        "  model.trainable = False\n",
        "  predictions = tf.keras.layers.Dense(num_classes,activation=\"softmax\")(model.output)\n",
        "  return tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  batch_size = 32\n",
        "  epochs = 2\n",
        "  num_classes = 10\n",
        "\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "  train_dataset = data_generator(x_train, y_train, batch_size)\n",
        "  test_dataset = data_generator(x_test, y_test, batch_size)\n",
        "\n",
        "  xception = model(num_classes)\n",
        "  optimizers = tf.keras.optimizers.Adam()\n",
        "  xception.compile(loss='sparse_categorical_crossentropy',optimizer=optimizers)\n",
        "\n",
        "  start_time = time()\n",
        "  xception.fit(train_dataset, epochs=epochs, steps_per_epoch=len(x_train)//batch_size,\n",
        "              validation_data=test_dataset,validation_steps=len(x_test)//batch_size)\n",
        "  end_time = time()\n",
        "\n",
        "  print(\"Time without xla and mpt with fp32\",end_time-start_time)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1562/1562 [==============================] - 31s 16ms/step - loss: 2.1950 - val_loss: 1.9621\n",
            "Epoch 2/2\n",
            "1562/1562 [==============================] - 25s 16ms/step - loss: 1.9244 - val_loss: 1.8520\n",
            "Time without xla and mpt with fp32 55.788514852523804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp5CDaM9iZaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52229a6-b9f1-46fe-e696-c5ebfe634f9a"
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit\"\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.experimental.set_policy(policy)\n",
        "\n",
        "def data_generator(features,labels,batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(((features/255),labels))\n",
        "  dataset = dataset.shuffle(buffer_size=len(labels)+1)\n",
        "  dataset = dataset.batch(batch_size=batch_size,\n",
        "                          drop_remainder=True)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return dataset\n",
        "\n",
        "def model(num_classes):  \n",
        "  model_input = tf.keras.layers.Input(shape=(32,32,3),dtype=tf.float16)\n",
        "  model = tf.keras.applications.ResNet50(include_top=False,\n",
        "                                          pooling='avg',\n",
        "                                         input_tensor=model_input)\n",
        "  model.trainable = False\n",
        "  x = tf.keras.layers.Dense(num_classes)(model.output)\n",
        "  predictions = tf.keras.layers.Activation('softmax', dtype=tf.float32)(x)\n",
        "  return tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  batch_size = 32\n",
        "  epochs = 2\n",
        "  num_classes = 10\n",
        "\n",
        "  (x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "  train_dataset = data_generator(x_train, y_train, batch_size)\n",
        "  test_dataset = data_generator(x_test, y_test, batch_size)\n",
        "\n",
        "  optimizer = tf.optimizers.Adam()\n",
        "  optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
        "\n",
        "  xception = model(num_classes)\n",
        "  xception.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer)\n",
        "\n",
        "  start_time = time()\n",
        "  xception.fit(train_dataset, epochs=epochs, steps_per_epoch=len(x_train)//batch_size,\n",
        "              validation_data=test_dataset,validation_steps=len(x_test)//batch_size)\n",
        "  end_time = time()\n",
        "  print(\"Time with xla and mpt with fp16\",end_time-start_time)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1562/1562 [==============================] - 26s 13ms/step - loss: 2.1972 - val_loss: 2.0195\n",
            "Epoch 2/2\n",
            "1562/1562 [==============================] - 18s 12ms/step - loss: 1.9323 - val_loss: 1.8927\n",
            "Time with xla and mpt with fp16 44.07524275779724\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}